__author__ = 'Vamshi'
__author__ = 'Vamshi'

import sys
import os
import numpy as np
import cv2
import matplotlib.pyplot as plt

no_of_docs = 10


def getsurfdata(path):
    """
    This function extracts the fft data from the wav files

    Parameters:
    -----------
    path - path to get the directory name of the songs present "E:\UNM\CS 529 - Intro to Machine Learning\Assignment 3\opihi.cs.uvic.ca\sound\genres"

    Returns:
    --------
    fftdata - fft data matrix of size (600,1000)
    """
    classesmatrix = np.zeros((no_of_docs, 1))                   # Stores the song, genre information in classesmatrix.txt file -> Line number as song index, genre
    surfdata = []       # Matrix (600,1000) to store the fft features information of all the songs in 6 genres
    fileindex = 0                                               # to store the current offset of the song
    surf = cv2.SIFT(400)
    for subdir, dirs, files in os.walk(path):                   # Traversing all the files in 6 genres
        for f in files:
            if f.endswith('.jpeg'):
                print "Processing file : " + f
                # Find keypoints and descriptors directly
                img = cv2.imread(os.path.join(subdir, f),0)
                kp, des = surf.detectAndCompute(img, None)
                surfdata.append(kp)
    return surfdata

def kfold(data, numberoffolds):
    """
    This function splits the fft data into train and test data. Generates 10 sets of data.

    Parameters:
    -----------
    data            - fft/fft20/mfcc data matrix
    numberoffolds   - k-fold cross validation size

    Returns:
    --------
    folddata        - k-fold data (k sets of data)

    Notes:
    -------
    Separates every 9 fft data into 'train' and every 10th fft data into 'test'. Like this, 10 sets of data is generated for 10 folds. One such fold example is given below.
    Eg: (train, test) = ({1,2,3,...,9,11,12,...,19,21,22,....599}, {0,10,20,30,....590})
    """
    folddata = []       # Array to store fold data
    for i in range(numberoffolds):
        train = []                                                   # Store the train data
        test = []                                                    # Store the test data
        testclasses = []
        for j in range(len(data)):                                   # Generates the data each fold. Explained this in Notes above.
            if (j - i) % 10 == 0:
                test.append(data[j])
            else:
                train.append(data[j])
        folddata.append((train, test, testclasses))
    return folddata


def savesurfdatatofile(fftdata):
    """
    This function saves the data into a txt file.

    Parameters:
    -----------
    fftdata - fft data matrix (600,1000) which is generated by the function getsurfdata()
    """
    thefile = open('surfdata.txt', 'w')
    for item in fftdata:
        thefile.write("%s\n" % item)


def loadfftdata(f):
    """
    This function loads the fft data from fft data file.

    Parameters:
    -----------
    f - fft data filename to be loaded
    """
    thefile = open(f, 'w')
    return thefile


def trainfn(train, tempweights, eta, lmda):
    """
    This function generates the updated weight matrix based on the train data using
    single step of the gradient descent of the logistic regression algorithm

    Parameters:
    -----------
    train       - train or test data
    tempweights - weight matrix
    eta         - learning rate
    lmda        - constant that determines the strength of the penalty term

    Returns:
    ---------
    updatedweightmatrix - Updated weight matrix
    """
    deltamatrix = np.zeros((len(genres), len(train)))
    count = 0
    for i in range(len(genres)):
        for j in range(len(train)):
            if j >= count and j < count + 90:
                deltamatrix[i][j] = 1
        count += 90
    p = np.exp(tempweights.dot(np.transpose(train)))        # exp(W.transpose(X)) - gives Conditional data likelihood - P(Y/W, X)

    for i in range(len(p[0])):     # This loop sets 1's in the last row of matrix 'p'.
        p[len(p)-1][i] = 1

    for i in range(len(p[0])):     # Divide every column value by it's sum.
        p[:, i] = p[:, i]/np.sum(p[:, i])

    errormatrix = (deltamatrix - p).dot(train)                            # Calculate error matrix (Delta - P(Y/W, X)X)
    intermatrix = eta * (errormatrix - lmda * tempweights)                # eta * ((errormatrix - Wt)
    updatedweightmatrix = np.add(tempweights, intermatrix)                # Wt + intermatrix
    return updatedweightmatrix


def testfn(tempweights, test):
    """
    This function classifies the test data based on logistic regression algorithm.

    Parameters:
    -----------
    tempweights - trained weight matrix used to classify the songs.
    test        - test data from a fold that has to be classified.

    Returns:
    ---------
    newtestclasses - returns the classified labels of the test data.
    """
    p = np.exp(tempweights.dot(np.transpose(test)))         # exp(W.transpose(X)) - gives Conditional data likelihood - P(Y/W, X)

    for i in range(len(p[0])):                  # This loop sets 1's in the last row of matrix 'p'.
        p[len(p)-1][i] = 1

    for i in range(len(p[0])):                  # Divide every column value by it's sum.
        p[:, i] = p[:, i]/np.sum(p[:, i])

    newtestclasses = np.zeros((len(test), 1))   # matrix to store the classified labels of the genres.

    for i in range(len(p[0])):                  # This loop finds the maximum value in a column of P (i.e., column represents index of data) and corresponding maximum value index (row) is taken as the label (genre) of that data.
        maxv = 0
        for j in range(len(p)):
            if p[j][i] > maxv:
                maxv = p[j][i]
                maxj = j
        newtestclasses[i] = maxj                # Array to store the labels
    return newtestclasses


def calc_conf_acc(testclasses, newtestclasses):
    """
    This function computes the Confusion Matrix and Accuracy rate.

    Parameters:
    -----------
    testclasses     - test labels/classes from the genre data.
    newtestclasses  - computed test labels/classes from logistic regression algorithm.

    Returns:
    ---------
    confusionmatrix - Confusion matrix based on testclasses and newtestclasses.
    accuracy        - Accuracy rate
    """
    confusionmatrix = np.zeros((len(genres), len(genres)))
    correct = 0
    for i in range(len(testclasses)):
        o = int(testclasses[i])
        n = int(newtestclasses[i])
        confusionmatrix[o][n] += 1
        if testclasses[i] == newtestclasses[i]:
            correct += 1
    return confusionmatrix, float(correct)/len(testclasses)


def processdata(data):
    """
    This function is the entry point to start the computations.

    Parameters:
    -----------
    data            - fft/fft20/mfcc data
    no_of_features  - number of features that have to be computed.
    """
    # folddata = kfold(data, 10)   # 10-fold cross validation
    eta = 0.01                      # Initializing learning rate
    eta_new = 0.01
    lmda = 0.001
    it = 300                        # Number of iterations for each fold to determine weight matrix
    eachfoldmaxaccuracies = []      # Array to store maximum accuracies obtained for each fold
    eachfoldmaxconfmatrices = []    # Array to store Confusion Matrix at maximum accuracies obtained for each fold
    for i in range(len(folddata)):              # Iterate over 10 folds of data
        weights = np.zeros((len(genres), no_of_features + 1))   # Initialize weights matrix with all zeros.
        train, test, testclasses = folddata[i]                  # Generate the k-fold data (10)
        train = normalize(train)                                # Normalize the train data
        test = normalize(test)                                  # Normalize the test data
        tempweights = weights[:]                                # Re-initialize weights matrix to all zeros.
        maxaccuracy = 0                                         # variable to store max-accuracy per fold.
        for j in range(it):                                     # Iterate the process for gradient descent (used in trainfn() function)
            print "Current Fold : " + str(i)
            print "Iteration : " + str(j)
            eta = eta_new / (1 + float(j) / it)                     # Calculate eta based on number of iterations
            tempweights = trainfn(train, tempweights, eta, lmda)    # generates the updated weight matrix based on the train data using single step of the gradient descent of the logistic regression algorithm
            newtestclasses = testfn(tempweights, test)              # classifies the test data based on the weight matrix obtained from the previous step
            confmatrix, accuracy = calc_conf_acc(testclasses, newtestclasses)   # Compute Confusion matrix and Accuracy
            if accuracy > maxaccuracy:                              # Calculate Maxaccuracy in the current fold and store the respective Confusion matrix in maxconfmatrix variable.
                maxaccuracy = accuracy
                maxconfmatrix = confmatrix
            print "Accuracy  : " + str(accuracy)
            print "Confusion Matrix : \n" + str(confmatrix)
        eachfoldmaxaccuracies.append(maxaccuracy)
        eachfoldmaxconfmatrices.append(maxconfmatrix)
    print "==============================================="
    for i in range(len(eachfoldmaxaccuracies)):                     # Print the max accuracy and respective confusion matrix for each fold.
        print "\n"
        print "Fold " + str(i) + " max accuracy : " + str(eachfoldmaxaccuracies[i])
        print "Confusion Matrix : "
        print eachfoldmaxconfmatrices[i]
    print "Avg of all folds accuracies : " + str(np.average(eachfoldmaxaccuracies))


if __name__ == '__main__':
    if os.path.isfile('surfdata.txt'):
        print "surfdata.txt is already present. Using this file."
        processdata(loadfftdata("surfdata.txt"))
        exit(0)
    else:
        print "surfdata.txt is not present. Creating one."
        savesurfdatatofile(getsurfdata('E:/UNM/CS 529 - Intro to Machine Learning/Assignment 4/Data/sample'))
        processdata(loadfftdata("surfdata.txt"))
        exit(0)